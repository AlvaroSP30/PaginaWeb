<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TherapyMeet: Conectando emociones y tecnolog铆a en cada sesi贸n</title>
    <link rel="stylesheet" href="exposicion.css">
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700;800&display=swap" rel="stylesheet">
</head>
<body class="font-inter antialiased text-gray-800 bg-gray-50">

    <nav class="bg-white shadow-md py-4 sticky top-0 z-50">
        <div class="container mx-auto px-6 flex justify-between items-center">
            <a href="#" class="text-2xl font-bold bg-emerald-800">TherapyMeet</a>
            <ul class="flex space-x-6">
                <li><a href="#contexto" class="hover:text-blue-600">Contexto</a></li>
                <li><a href="#cnn" class="hover:text-blue-600">CNN Personalizada</a></li>
                <li><a href="#entrenamiento" class="hover:text-blue-600">Entrenamiento</a></li>
                <li><a href="#enlaces" class="hover:text-blue-600">Enlaces</a></li>
            </ul>
        </div>
    </nav>

    <header class="hero-header py-24 text-white text-center">
        <div class="container mx-auto px-6">
            <h1 class="text-4xl md:text-6xl font-extrabold mb-4 leading-tight">TherapyMeet: Conectando emociones y tecnolog铆a en cada sesi贸n </h1>
            <p class="text-xl md:text-2xl opacity-90">Una soluci贸n innovadora para la detecci贸n de emociones en tiempo real durante sesiones de terapia online.</p>
        </div>
    </header>

    <section id="contexto" class="py-16 bg-gray-100">
        <div class="container mx-auto px-6 max-w-4xl">
            <h2 class="section-title text-4xl md:text-5xl font-extrabold text-center mb-12 text-gray-900">
                Contexto del Proyecto
            </h2>

            <div class="bg-white p-8 rounded-xl shadow-lg mb-8">
                <h3 class="text-2xl font-bold text-gray-900 mb-4 flex items-center">
                    <i class="fas fa-question-circle text-blue-600 mr-3"></i> Problema
                </h3>
                <p class="text-lg text-gray-700 leading-relaxed">
                    Uno de los retos a los que se enfrentan los psic贸logos en las sesiones de terapia en l铆nea es la imposibilidad de observar las emociones y reacciones de los pacientes en tiempo real, algo que resulta m谩s f谩cil de hacer en un entorno presencial. Esta limitaci贸n puede dificultar la empat铆a y la adaptaci贸n de las estrategias terap茅uticas.
                </p>
            </div>

            <div class="bg-white p-8 rounded-xl shadow-lg">
                <h3 class="text-2xl font-bold text-gray-900 mb-4 flex items-center">
                    <i class="fas fa-lightbulb text-blue-600 mr-3"></i> Contexto de la Soluci贸n
                </h3>
                <p class="text-lg text-gray-700 leading-relaxed mb-4">
                    Nuestro sistema se encarga de reconocer emociones de los pacientes en tiempo real durante las sesiones online. Esto proporciona a los terapeutas una herramienta valiosa para complementar su percepci贸n y ajustar su enfoque de manera m谩s efectiva.
                </p>
                <h4 class="text-xl font-semibold text-gray-800 mb-2">Emociones Detectadas:</h4>
                <ul class="list-disc list-inside text-base text-gray-600 space-y-1 ml-4">
                    <li>Felicidad </li>
                    <li>Tristeza </li>
                    <li>Neutralidad </li>
                    <li>Enfado </li>
                    <li>Sorpresa </li>
                    <li>Asco あ</li>
                    <li>Miedo </li>
                </ul>
            </div>
        </div>
    </section>

    <section id="cnn" class="py-16 bg-gray-50">
        <div class="container mx-auto px-6 max-w-4xl">
            <h2 class="section-title text-4xl md:text-5xl font-extrabold text-center mb-12 text-gray-900">
                Arquitectura de la CNN Personalizada
            </h2>
            <div class="bg-white p-8 rounded-xl shadow-lg">
                <p class="text-lg text-gray-700 leading-relaxed mb-4">
                    Hemos desarrollado una red neuronal convolucional (CNN) personalizada y optimizada para la detecci贸n precisa de las 7 emociones clave.
                </p>
                <ul class="list-disc list-inside text-base text-gray-600 space-y-3 ml-4">
                    <li>
                        <strong>Capas Convolucionales:</strong> Seis capas convolucionales con tama帽os de kernel de 33 y 11 para una extracci贸n robusta de caracter铆sticas.
                    </li>
                    <li>
                        <strong>Normalizaci贸n y Activaci贸n:</strong> Incorporamos <strong>Batch Normalization</strong> y la funci贸n de activaci贸n <strong>ReLU</strong> despu茅s de cada capa convolucional para mejorar la estabilidad y velocidad del entrenamiento.
                    </li>
                    <li>
                        <strong>Reducci贸n de Dimensionalidad:</strong> Utilizamos <strong>Max Pooling (22)</strong> para reducir la dimensionalidad de los mapas de caracter铆sticas y hacer el modelo m谩s eficiente y menos propenso al sobreajuste.
                    </li>
                    <li>
                        <strong>Capas Densas:</strong> Incluimos dos capas densas (fully connected) con funci贸n de activaci贸n ReLU.
                    </li>
                    <li>
                        <strong>Regularizaci贸n:</strong> Una capa de <strong>Dropout (0.2)</strong> se aplica para evitar el sobreajuste, mejorando la capacidad de generalizaci贸n del modelo.
                    </li>
                    <li>
                        <strong>Capa de Salida:</strong> La capa final cuenta con <strong>7 neuronas</strong>, cada una representando una de las emociones que el sistema es capaz de detectar (feliz, triste, neutral, enojado, sorpresa, disgusto, miedo).
                    </li>
                </ul>
            </div>
        </div>
    </section>

    <section id="entrenamiento" class="py-16 bg-gray-100">
        <div class="container mx-auto px-6 max-w-4xl">
            <h2 class="section-title text-4xl md:text-5xl font-extrabold text-center mb-12 text-gray-900">
                Etapas del Entrenamiento y Evaluaci贸n
            </h2>

            <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                <div class="bg-white p-8 rounded-xl shadow-lg">
                    <h3 class="text-2xl font-bold text-gray-900 mb-4 flex items-center">
                        <i class="fas fa-cogs text-blue-600 mr-3"></i> Preprocesamiento
                    </h3>
                    <ul class="list-disc list-inside text-base text-gray-600 space-y-3 ml-4">
                        <li>
                            <strong>Aumento de Datos:</strong> Se aplicaron transformaciones como rotaci贸n, zoom y cambios de color utilizando <strong>ImageDataGenerator de Keras</strong> para enriquecer el dataset y mejorar la robustez del modelo.
                        </li>
                        <li>
                            <strong>Divisi贸n del Dataset:</strong> El dataset original de <strong>40,254 im谩genes</strong> fue cuidadosamente dividido en conjuntos de entrenamiento, validaci贸n y prueba para asegurar una evaluaci贸n imparcial del modelo.
                        </li>
                    </ul>
                </div>

                <div class="bg-white p-8 rounded-xl shadow-lg">
                    <h3 class="text-2xl font-bold text-gray-900 mb-4 flex items-center">
                        <i class="fas fa-brain text-blue-600 mr-3"></i> Entrenamiento
                    </h3>
                    <ul class="list-disc list-inside text-base text-gray-600 space-y-3 ml-4">
                        <li>
                            <strong>Optimizador:</strong> Se utiliz贸 el optimizador <strong>Adam</strong> por su eficiencia y buenos resultados en problemas de clasificaci贸n de im谩genes.
                        </li>
                        <li>
                            <strong>pocas:</strong> El modelo fue entrenado durante <strong>150 茅pocas</strong>, permitiendo un aprendizaje profundo y convergencia de los pesos.
                        </li>
                        <li>
                            <strong>M茅tricas de Monitoreo:</strong> Se monitorearon la <strong>precisi贸n (accuracy) y la p茅rdida (loss)</strong> durante todo el proceso de entrenamiento para evaluar el rendimiento.
                        </li>
                    </ul>
                </div>
            </div>

            <div class="bg-white p-8 rounded-xl shadow-lg mt-8">
                <h3 class="text-2xl font-bold text-gray-900 mb-4 flex items-center">
                    <i class="fas fa-chart-line text-blue-600 mr-3"></i> Evaluaci贸n
                </h3>
                <p class="text-lg text-gray-700 leading-relaxed">
                    Tras el entrenamiento, nuestro modelo alcanz贸 una <strong>precisi贸n final del 70%</strong> en datos reales. Esto demuestra una capacidad significativa para identificar correctamente las emociones en entornos pr谩cticos, lo que lo convierte en una herramienta prometedora para el apoyo en terapias online.
                </p>
            </div>
        </div>
    </section>

    <section id="enlaces" class="py-16 bg-gray-50 text-center">
        <div class="container mx-auto px-6 max-w-2xl">
            <h2 class="section-title text-4xl md:text-5xl font-extrabold text-center mb-12 text-gray-900">
                Recursos del Proyecto
            </h2>
            <div class="flex flex-col md:flex-row justify-center items-center gap-8">
                <a href="https://github.com/AlvaroSP30/Reconocimiento_Emociones.git" target="_blank" class="bg-gray-800 text-white px-8 py-4 rounded-lg shadow-lg hover:bg-gray-700 transition-colors duration-300 flex items-center text-xl font-semibold">
                    <i class="fab fa-github mr-3 text-2xl"></i> Repositorio en GitHub
                </a>
            </div>
            <p class="text-sm text-gray-500 mt-4"></p>
        </div>
    </section>

    <footer class="footer py-6 bg-gray-800 text-white text-center">
        <div class="container mx-auto px-6">
            <p>Copyright 漏 Alvaro Pinares Taype 2025</p>
        </div>
    </footer>

    <script src="exposiciones.js"></script>
</body>
</html>